# 萌拉数据采集项目分析与重构方案

> 生成时间：2026-02-04  
> 目标：建立健壮性高、效率高的数据采集与存储系统

---

## 一、项目现状分析

### 1.1 当前架构

```
Frontend (React) → Backend (FastAPI) → MongoDB + Redis + 外部采集服务
```

核心模块：
- `main.py` - API 路由
- `scheduler.py` - 定时任务（APScheduler）
- `mengla_domain.py` - 核心采集逻辑
- `mengla_client.py` - 外部服务调用

### 1.2 核心问题

| 问题 | 现状 | 影响 |
|------|------|------|
| **定时采集** | 凌晨2:10单点执行，无自动重试 | 失败后需人工干预 |
| **任务执行** | 串行采集所有类目 | 效率低，耗时长 |
| **MongoDB** | 5个重复集合，缺少catId索引 | 按类目查询慢 |
| **数据清理** | 无TTL索引 | 数据无限增长 |
| **Redis缓存** | 固定24h TTL，key格式不规范 | 缓存效率低 |
| **代码质量** | mengla_domain.py 580行 | 职责过重，难维护 |
| **容错机制** | 无熔断降级 | 外部故障会雪崩 |

---

## 二、需求清单

### 2.1 核心需求（用户提出）

| 需求 | 优先级 |
|------|--------|
| 凌晨定时采集（可配置时间窗口） | P0 |
| MongoDB+Redis 颗粒度优化 | P0 |
| 健壮性高（故障自愈、重试、监控） | P0 |
| 效率高（并发、智能缓存） | P0 |

### 2.2 补充需求（系统分析）

| 需求 | 优先级 |
|------|--------|
| 采集任务管理（优先级、分片、暂停/恢复） | P1 |
| 数据生命周期（自动归档、清理） | P1 |
| 监控与告警（成功率、延迟） | P1 |
| 配置中心（无需重启生效） | P1 |
| API 限流保护 | P2 |
| 数据完整性校验 | P2 |

---

## 三、目标架构

### 3.1 架构升级

```
┌─────────────────────────────────────────────────────────────┐
│                      配置中心                               │
│  采集时间窗口 / 类目开关 / 缓存TTL策略                      │
└─────────────────────────┬───────────────────────────────────┘
                          │
┌─────────────────────────┼───────────────────────────────────┐
│                   采集调度层                                │
│  ┌────────────┐ ┌────────────┐ ┌────────────┐              │
│  │凌晨批量采集│ │增量补数采集│ │手动触发采集│              │
│  │(0:30-5:00) │ │(每4h检查)  │ │(API触发)   │              │
│  └─────┬──────┘ └─────┬──────┘ └─────┬──────┘              │
│        └──────────────┼──────────────┘                     │
│                 ┌─────▼─────┐                              │
│                 │ 任务队列  │ ← Redis Stream               │
│                 └─────┬─────┘                              │
│        ┌──────────────┼──────────────┐                     │
│        ▼              ▼              ▼                     │
│   [Worker 1]    [Worker 2]    [Worker N] ← 可水平扩展      │
└─────────────────────────────────────────────────────────────┘
                          │
┌─────────────────────────┼───────────────────────────────────┐
│                   数据访问层                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │              智能缓存层 (三级)                       │   │
│  │  L1 本地(进程内) → L2 Redis(分布式) → L3 MongoDB    │   │
│  └─────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
                          │
┌─────────────────────────┼───────────────────────────────────┐
│                   监控告警层                                │
│  采集成功率(>99%) / 数据延迟(<30min) / 服务健康            │
│                    ↓ 异常自动告警                          │
└─────────────────────────────────────────────────────────────┘
```

### 3.2 MongoDB 数据模型优化

**统一集合**：`mengla_data`（合并原有5个集合）

| 字段 | 说明 |
|------|------|
| action | high/hot/chance/view/trend |
| cat_id | 类目ID（空=全类目） |
| granularity | day/month/quarter/year |
| period_key | 20260204/202602/2026Q1/2026 |
| data | 原始数据 |
| data_hash | MD5指纹（变更检测） |
| source | fresh/cache/backfill |
| collect_duration_ms | 采集耗时 |
| created_at / updated_at | 时间戳 |
| expired_at | TTL自动清理时间 |

**索引设计**：

| 索引 | 用途 |
|------|------|
| {action, cat_id, granularity, period_key} UNIQUE | 主查询 |
| {cat_id, created_at} | 类目维度查询 |
| {action, granularity, period_key} | 跨类目聚合 |
| {expired_at} TTL | 自动过期清理 |
| {updated_at} | 增量同步 |

**数据保留策略**：
- day: 30天 / month: 90天 / quarter: 1年 / year: 2年

### 3.3 Redis 缓存设计

| 数据结构 | Key 格式 | 用途 |
|---------|---------|------|
| String | `mengla:data:{action}:{cat_id}:{granularity}:{period_key}` | 数据缓存 |
| String | `mengla:lock:{...}` | 分布式锁（防重复采集） |
| Stream | `mengla:task_queue` | 任务队列 |
| Hash | `mengla:stats:{date}` | 采集统计 |
| String | `mengla:circuit:{service}` | 熔断状态 |
| String | `mengla:rate:{api_key}:{window}` | 频控计数 |

**TTL 策略**（按颗粒度）：
- day: 4小时 / month: 24小时 / quarter: 7天 / year: 30天

---

## 四、详细重构方案

### 4.1 阶段一：基础架构优化（P0）

#### 4.1.1 定时采集系统

**采集任务配置**：

| 任务 | Cron | 接口 | 颗粒度 | 优先级 |
|------|------|------|--------|--------|
| 每日主采集 | `30 0 * * *` | 全部 | day | 1 |
| 月度采集 | `0 1 1 * *` | 全部 | month | 2 |
| 季度采集 | `0 2 1 1,4,7,10 *` | 全部 | quarter | 3 |
| 年度采集 | `0 3 1 1 *` | 全部 | year | 4 |
| 补数检查 | `0 */4 * * *` | 全部 | day,month | 8 |

**关键特性**：
- 可配置采集窗口（默认 00:30-05:00）
- 并发控制（默认5并发）
- 自动重试（3次，指数退避）
- 任务优先级

#### 4.1.2 三级缓存架构

```
请求 → L1本地缓存(5min) → L2 Redis → L3 MongoDB → 外部采集
         ↑                    ↑           ↑
         └──── 回填缓存 ───────┴───────────┘
```

**L1 本地缓存**：
- 容量：1000条
- TTL：5分钟
- 淘汰策略：LRU

### 4.2 阶段二：健壮性增强（P0）

#### 4.2.1 重试机制

| 配置项 | 默认值 |
|--------|--------|
| 最大重试次数 | 3 |
| 基础延迟 | 1秒 |
| 最大延迟 | 60秒 |
| 退避策略 | 指数退避 + 抖动 |
| 可重试异常 | ConnectionError, TimeoutError |

#### 4.2.2 熔断器

| 配置项 | 默认值 |
|--------|--------|
| 失败阈值（触发熔断） | 5次 |
| 成功阈值（恢复） | 3次 |
| 熔断超时 | 1分钟 |
| 半开状态探测数 | 3次 |

**状态流转**：
```
CLOSED → (连续5次失败) → OPEN → (1分钟后) → HALF_OPEN → (3次成功) → CLOSED
                                    ↓ (探测失败)
                                   OPEN
```

#### 4.2.3 统一日志

**结构化字段**：
- timestamp / level / logger / message
- trace_id（请求追踪）
- action / cat_id / granularity / period_key
- source / duration_ms / success / error

### 4.3 阶段三：效率优化（P1）

#### 4.3.1 并发采集

| 配置项 | 默认值 |
|--------|--------|
| 最大并发数 | 5 |
| 单任务超时 | 5分钟 |
| 批次大小 | 10 |

**采集流程**：
1. 检查 L1/L2 缓存 → 命中返回
2. 检查 MongoDB → 命中则回填缓存并返回
3. 调用外部采集（带熔断保护）
4. 写入 MongoDB + 缓存

#### 4.3.2 缓存预热

触发时机：
- 服务启动
- 凌晨采集完成后
- 热点类目手动预热

### 4.4 阶段四：监控告警（P1）

#### 4.4.1 指标收集

| 指标 | 说明 |
|------|------|
| total_tasks | 总任务数 |
| success_count / fail_count | 成功/失败数 |
| cache_hit_count | 缓存命中数 |
| avg_duration_ms | 平均耗时 |

#### 4.4.2 告警规则

| 规则 | 条件 | 级别 | 冷却 |
|------|------|------|------|
| 成功率低 | <95% | WARNING | 10min |
| 成功率严重下降 | <80% | CRITICAL | 5min |
| 延迟过高 | >30s | WARNING | 10min |
| 缓存命中率低 | <50% | INFO | 30min |

---

## 五、实施路线

### 5.1 阶段划分

| 阶段 | 周期 | 内容 |
|------|------|------|
| Phase 1 | 1周 | MongoDB数据模型 + Redis缓存层 + 定时调度 |
| Phase 2 | 1周 | 重试机制 + 熔断器 + 结构化日志 |
| Phase 3 | 1周 | 并发采集 + 缓存预热 + 查询优化 |
| Phase 4 | 1周 | 指标收集 + 告警规则 + 仪表盘 |

### 5.2 迁移策略

1. **数据迁移**：新旧集合并行 → 灰度切换 → 一致性校验
2. **代码部署**：功能开关控制 → 逐步放量 → 快速回滚
3. **监控验证**：成功率/延迟/资源对比

---

## 六、关键配置

```yaml
scheduler:
  timezone: Asia/Shanghai
  collect_window: { start: "00:30", end: "05:00" }
  concurrency: 5
  retry_times: 3

cache:
  ttl: { day: 4h, month: 24h, quarter: 7d, year: 30d }
  l1: { max_size: 1000, ttl: 5m }

circuit_breaker:
  failure_threshold: 5
  success_threshold: 3
  timeout: 1m

alerting:
  rules:
    - { name: low_success_rate, threshold: 95%, level: warning }
    - { name: high_latency, threshold: 30s, level: warning }
```

---

## 七、改进对比

| 维度 | 改进前 | 改进后 |
|------|--------|--------|
| 定时采集 | 单一时间点，无重试 | 可配置窗口，自动重试 |
| 数据模型 | 5个重复集合 | 统一集合+优化索引 |
| 缓存策略 | 固定24h TTL | 三级缓存+智能TTL |
| 错误处理 | 分散简单 | 统一+熔断+降级 |
| 采集效率 | 串行 | 并发+优先级 |
| 监控告警 | 无 | 完整指标+规则告警 |

**预期收益**：
- 可用性：采集成功率 >99%
- 性能：缓存命中 <10ms
- 运维：自动化监控告警
- 扩展：支持水平扩展 Worker
